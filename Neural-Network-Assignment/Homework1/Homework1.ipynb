{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'nngraph'\n",
    "require 'torch'\n",
    "require 'image'\n",
    "\n",
    "-- Create a table of options\n",
    "opt = {\n",
    "    data_dir = './',\n",
    "\n",
    "    -- model parameters\n",
    "\n",
    "    ninput = 310,\n",
    "    nhidden = 100,\n",
    "    noutput = 3,\n",
    "    \n",
    "    -- optimization parameters\n",
    "\n",
    "    -- learning rate\n",
    "    learning_rate = 1e-3,\n",
    "    -- learning rate decay\n",
    "    learning_rate_decay = 0.97,\n",
    "    -- in number of epochs, when to start decaying the learning rate\n",
    "    learning_rate_decay_after = 10,\n",
    "    -- decay rate for rmsprop\n",
    "    decay_rate = 0.95,\n",
    "       \n",
    "    -- batch size\n",
    "    batch_size = 32,\n",
    "    -- number of full passes through the training data\n",
    "    max_epochs = 20,\n",
    "    -- clip gradients at\n",
    "    grad_clip = 5,\n",
    "   \n",
    "    -- bookkeeping\n",
    "\n",
    "    -- torch manual random number generator seed\n",
    "    seed = 123,\n",
    "    -- how many steps/minibatches between printing out the loss\n",
    "    print_every = 50,\n",
    "    -- every how many iterations should we evaluate on validation data?\n",
    "    eval_val_every = 50,\n",
    "    -- output directory where checkpoints get written\n",
    "    checkpoint_dir = 'cv',\n",
    "    -- filename to autosave the checkpont to. Will be inside checkpoint_dir/\n",
    "    savefile = 'mlqp',\n",
    "\n",
    "}\n",
    "\n",
    "torch.setnumthreads(2)\n",
    "torch.manualSeed(opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matio = require 'matio'\n",
    "require 'math'\n",
    "require 'torch'\n",
    "require 'math'\n",
    "\n",
    "MinibatchLoader = {}\n",
    "MinibatchLoader.__index = MinibatchLoader\n",
    "\n",
    "function MinibatchLoader.create(batch_size)\n",
    "    local self = {}\n",
    "    setmetatable(self, MinibatchLoader)\n",
    "\n",
    "    -- construct a tensor with all the data\n",
    "    print('loading data files...')\n",
    "    local train_input = matio.load('hw1/train_test/train_data.mat')\n",
    "    local train_label = matio.load('hw1/train_test/train_label.mat')\n",
    "    \n",
    "    train_label.train_label = train_label.train_label + 2\n",
    "\n",
    "    self.x_batches = torch.Tensor(train_input.train_data:size())\n",
    "    self.y_batches = torch.Tensor(train_label.train_label:size())\n",
    "    --     shuffle the data\n",
    "    shuffle = torch.randperm(train_input.train_data:size(1))\n",
    "    for i = 1,train_input.train_data:size(1) do\n",
    "        self.x_batches[i] = train_input.train_data[shuffle[i]]\n",
    "        self.y_batches[i] = train_label.train_label[shuffle[i]]\n",
    "    end\n",
    "    \n",
    "    self.nbatches = math.floor(self.x_batches:size(1)/batch_size)\n",
    "    assert(self.x_batches:size(1) == self.y_batches:size(1))\n",
    "\n",
    "    self.current_batch = 0\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    \n",
    "    --  feature normalization\n",
    "    local mean = {}\n",
    "    local stdv = {}\n",
    "    for i = 1,self.x_batches:size(2) do\n",
    "        mean[i] = self.x_batches[{{},{i}}]:mean()\n",
    "        self.x_batches[{{},{i}}]:add(-mean[i])\n",
    "        stdv[i] = self.x_batches[{{},{i}}]:std()\n",
    "        self.x_batches[{{},{i}}]:div(stdv[i])\n",
    "    end\n",
    "    \n",
    "    print('data load done.')\n",
    "    collectgarbage()\n",
    "    return self\n",
    "end\n",
    "\n",
    "function MinibatchLoader:next_batch()\n",
    "    self.current_batch = (self.current_batch % self.nbatches) + 1\n",
    "    return self.x_batches[{{(self.current_batch-1)*self.batch_size+1,self.current_batch*self.batch_size},{}}], self.y_batches[{{(self.current_batch-1)*self.batch_size+1,self.current_batch*self.batch_size},{}}]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "function get_network(nhidden, ninput, noutput)\n",
    "    local input = nn.Identity()()\n",
    "    local square_input = nn.Square()(input)\n",
    "    \n",
    "    local hh1 = nn.Linear(ninput, nhidden)(square_input)\n",
    "    local hh2 = nn.Linear(ninput, nhidden)(input)\n",
    "    \n",
    "    local hh = nn.CAddTable()({hh1, hh2})\n",
    "    local h = nn.Sigmoid()(hh)\n",
    "    \n",
    "    local square_h = nn.Square()(h)\n",
    "    \n",
    "    local output1 = nn.Linear(nhidden, noutput)(square_h)\n",
    "    local output2 = nn.Linear(nhidden, noutput)(h)\n",
    "    \n",
    "    local output = nn.CAddTable()({output1, output2})\n",
    "    \n",
    "    nngraph.annotateNodes()\n",
    "    return nn.gModule({input}, {output}) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = {}\n",
    "model.mlqp = get_network(opt.nhidden, opt.ninput, opt.noutput)\n",
    "model.criterion = nn.CrossEntropyCriterion()\n",
    "\n",
    "params, grad_params = model.mlqp:getParameters()\n",
    "graph.dot(model.mlqp.fg, 'mlqp', 'mlqp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number of parameters in the model: 62806\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- initialization\n",
    "params:uniform(-0.08, 0.08) -- small numbers uniform\n",
    "print('number of parameters in the model: ' .. params:nElement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loading data files...\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "data load done.\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = MinibatchLoader.create(opt.batch_size)\n",
    "function feval(x)\n",
    "    if x ~= params then\n",
    "        params:copy(x)\n",
    "    end\n",
    "    grad_params:zero()\n",
    "\n",
    "    ------------------- forward pass -------------------\n",
    "    local data, label = loader:next_batch()\n",
    "    local output = model.mlqp:forward(data)\n",
    "    local loss = model.criterion:forward(output,label)\n",
    "\n",
    "    ------------------ backward pass -------------------\n",
    "    local doutput = model.criterion:backward(output, label)\n",
    "    model.mlqp:backward(data,doutput)\n",
    "    -- clip gradient element-wise\n",
    "    grad_params:clamp(-opt.grad_clip, opt.grad_clip)\n",
    "    \n",
    "--     grad_params:div(#data)\n",
    "--     loss = loss/#data\n",
    "    return loss, grad_params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision in Test Set 83.090379008746 % \t\n",
       "50/300 (epoch 0.167), train_loss = 0.00962227, grad/param norm = 3.9188e-03, time/batch = 0.00s\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Precision in Test Set 83.090379008746 % \t\n",
       "100/300 (epoch 0.333), train_loss = 0.00223159, grad/param norm = 9.7231e-04, time/batch = 0.00s\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Precision in Test Set 83.090379008746 % \t\n",
       "150/300 (epoch 0.500), train_loss = 0.00068660, grad/param norm = 3.4923e-04, time/batch = 0.00s\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Precision in Test Set 83.090379008746 % \t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "200/300 (epoch 0.667), train_loss = 0.00018212, grad/param norm = 7.9455e-05, time/batch = 0.00s\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Precision in Test Set 83.090379008746 % \t\n",
       "250/300 (epoch 0.833), train_loss = 0.00005818, grad/param norm = 2.5810e-05, time/batch = 0.00s\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Precision in Test Set 83.090379008746 % \t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "300/300 (epoch 1.000), train_loss = 0.00002039, grad/param norm = 1.0368e-05, time/batch = 0.00s\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- start optimization here\n",
    "require 'optim'\n",
    "function eval()\n",
    "-- read data\n",
    "    local test_input = matio.load('hw1/train_test/test_data.mat')\n",
    "    local test_label = matio.load('hw1/train_test/test_label.mat')\n",
    "    test_label.test_label = test_label.test_label + 2\n",
    "    \n",
    "        --  feature normalization\n",
    "    local mean = {}\n",
    "    local stdv = {}\n",
    "    for i = 1,test_input.test_data:size(2) do\n",
    "        mean[i] = test_input.test_data[{{},{i}}]:mean()\n",
    "        test_input.test_data[{{},{i}}]:add(-mean[i])\n",
    "        stdv[i] = test_input.test_data[{{},{i}}]:std()\n",
    "        test_input.test_data[{{},{i}}]:div(stdv[i])\n",
    "    end\n",
    "    \n",
    "    correct = 0\n",
    "    for i=1,test_label.test_label:size(1) do\n",
    "        local groundtruth = test_label.test_label[i]\n",
    "        local prediction = model.mlqp:forward(test_input.test_data[i])\n",
    "        local confidences, indices = torch.sort(prediction, true)\n",
    "        if groundtruth[1] == indices[1] then\n",
    "            correct = correct + 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    print('Precision in Test Set '.. 100*correct/test_label.test_label:size(1) .. ' % ')\n",
    "end\n",
    "\n",
    "\n",
    "train_losses = {}\n",
    "val_losses = {}\n",
    "local optim_state = {learningRate = opt.learning_rate, alpha = opt.decay_rate}\n",
    "local iterations = opt.max_epochs*loader.nbatches\n",
    "local loss0 = nil\n",
    "for i = 1, iterations do\n",
    "    local timer = torch.Timer()\n",
    "    local _, loss = optim.rmsprop(feval, params, optim_state)\n",
    "    local time = timer:time().real\n",
    "    -- exponential learning rate decay\n",
    "    if i % loader.nbatches == 0 and opt.learning_rate_decay < 1 then\n",
    "        if i >= opt.learning_rate_decay_after*loader.nbatches then\n",
    "            local decay_factor = opt.learning_rate_decay\n",
    "            optim_state.learningRate = optim_state.learningRate * decay_factor -- decay it\n",
    "--             print('decayed learning rate by a factor ' .. decay_factor .. ' to ' .. optim_state.learningRate)\n",
    "        end\n",
    "    end\n",
    "    -- every now and then or on last iteration\n",
    "    if i % opt.eval_val_every == 0 or i == iterations then\n",
    "        -- evaluate loss on validation data\n",
    "        local val_loss = eval()\n",
    "        val_losses[i] = val_loss\n",
    "    end\n",
    "\n",
    "    if i % opt.print_every == 0 then\n",
    "        print(string.format(\"%d/%d (epoch %.3f), train_loss = %6.8f, grad/param norm = %6.4e, time/batch = %.2fs\", i, iterations, i/iterations, loss[1], grad_params:norm() / params:norm(), time))\n",
    "    end\n",
    "   \n",
    "    if i % 10 == 0 then collectgarbage() end\n",
    "\n",
    "    -- handle early stopping if things are going really bad\n",
    "    if loss0 == nil then loss0 = loss[1] end\n",
    "    if loss[1] > loss0 * 3 then\n",
    "        print('loss is exploding, aborting.')\n",
    "        break -- halt\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
